---
layout: post
title: Stylized Post-Processing
excerpt_separator: <!--more-->
---
****
<div align="center">
    <img src="/images/PostProcessComparisonMain.png" width="900">
</div>

The visual quality of a game is a major contributing factor to how immersive the experience is. However, better graphical fidelity isn't always the answer to a more immersive experience as most games that attempt realism get stuck in the uncanny valley. The other approach is stylism. Instead of getting closer to realism, stylized games aim to exaggerate certain aspects and leave others up to interpretation. The purpose of this post-processing is to minimize the over-precision of 3D rendering to create a more stylized portrayal of a game. The picture above compares a scene without and with post-processing effects. The scene on the left has no post-processing effects and the scene on the right has color grading, vignette, fog, and the custom effects that this post will discuss.
<!--more-->



## The Basics
Before I go into specifics of the custom effects, I will explain the basics of how post-processing works. A post-processing effect is programmed in a shader language, HLSL in this case,  and defines how a single pixel should be displayed. These programs are referred to as shaders. The main input for this program is the main texture that is rendered from the main camera in the scene. This is the texture that is eventually displayed to the screen. The shader can access parameters set by the programmer, such as textures, colors, floating-point numbers and integers. 

Since the output of the shader is just the color for a single pixel, the code must be run for every pixel on the screen. This means that for a standard 1080p monitor, the shader must be run 2,073,600 times each frame. I am developing these effects with an emphasis on performance, so I do not want any significant difference in performance between it being on and off even at 500+ frames per second(fps). If the game is running at 500fps then the program must run 1,036,800,000 times each second. This is possible thanks to the power of graphics cards, but the performance of a post-processing effect can quickly get out of hand with complex effects.

If a shader is simple, such as multiplying the input pixel by a certain color to tint the image, then the performance degradation is negligible. On the other hand, if one run of a shader requires sampling several dozen pixels, and performing several dozen calculations to each, then the fps can drop massively. 


## Inspiration and Implementation
The idea for the custom effects started with the Kuwahara filter. The purpose of the Kuwahara filter is to reduce the noise in an image without blurring the image. During this process, it is able to smooth simplify forms. It accomplishes this by taking color samples of pixels in four regions surrounding the current pixel. The mean of the region with the lowest standard deviation becomes the new color for the current pixel. The number of samples used for each region is good for eliminating extreme noise, but it is overboard as a post-processing effect. The image below shows the difference between the standard Kuwahara and my custom implementation.

<div align="center">
    <img src="/images/PixelSampling.png" width="500">
</div>

My implementation uses a much more sparse sampling region to drastically improve performance. Getting the color from a pixel takes time, so fewer samples equates to higher performance. Also, since the effect calculates the mean and standard deviation for each region, fewer samples means fewer calculations. Each 7x7 region used in the custom version only samples four pixels compared to twenty-five pixels each region for the Kuwahara filter with 5x5 regions.

To improve the performance of the effect, I use the depth texture generated by the camera to limit the effect by changing the region size in certain circumstances. The region size is reduced from 7x7 to 5x5 for pixels that are within 5 meters from the camera to improve readability of small text on objects. The region size is also reduced from 7x7 to 5x5 for pixels that are between 70 meters and 300 meters from the camera because these pixels are partially covered by the fog effect. For pixels more than 300 meters away, the effect is not applied because the pixels are mostly or entirely covered by the fog effect. Lastly, the effect is not applied for the skybox because it is not affected by any objects and is a constant distance from the camera.

The custom Kuwahara filter does not create an as aggressively stylized effect, so I created another shader. The second shader is made to posterize the vibrance of the colors. The first step to posterize only the vibrance of the pixel is to convert its color from RGB (red, blue, green) to HSV (hue, saturation, vibrance). HSV is a representation of a color instead of the red, blue, and green values the LEDs in the monitor use to create a colored pixel. With HSV, I can posterize the vibrance of a color without affecting the other values. The shader performs a modulo operation on the vibrance to create the posterize effect. The calculated vibrance replaces the original vibrance and the color is converted back to RGB. The vibrance mod shader runs before the custom Kuwahara filter, so the input for the custom Kuwahara filter is the result of the vibrance mod shader. This results in an effect much more suited for real-time rendering.

